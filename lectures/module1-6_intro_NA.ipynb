{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d3a3d41",
   "metadata": {},
   "source": [
    "# 6) Introduction to Numerical Analysis \n",
    "\n",
    "Last Time:\n",
    "\n",
    "- Introduction to Finite Difference schemes\n",
    "- Evaluating derivatives\n",
    "- Taylor series and truncation error\n",
    "\n",
    "Today:\n",
    "1. Well-posedeness \n",
    "2. Introduction to Consistency  \n",
    "3. The leapfrog scheme \n",
    "4. Introduction to Accuracy   \n",
    "5. Introduction to Stability\n",
    "6. Introduction to Conditioning   \n",
    "7. Lax equivalence theorem  \n",
    "8. Higher-order schemes: the Method of Undetermined Coefficients\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2c7066",
   "metadata": {},
   "source": [
    "## 1. Well-posedeness\n",
    "\n",
    ":::{admonition} Definition\n",
    "The initial value problem (IVP) for the first order PDE $\\mathcal{P} u = 0$ is **well-posed** if for any time $T \\geq 0$, there is a constant $C_T$ such that any solution $u(t,x)$ satisfies\n",
    "\n",
    "$$\n",
    "\\int_{- \\infty}^{\\infty} |u(x,t)|^2 dx \\leq C_T \\int_{- \\infty}^{\\infty} |u(0,x)|^2 dx\n",
    "$$\n",
    "\n",
    "for $0 \\leq t \\leq T$.\n",
    ":::\n",
    "\n",
    "Meaning, an IVP is well-posed if it depends continuously upon its initial conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadf04b3",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Introduction to Consistency  \n",
    "\n",
    "Last time, we found one possible approximation to the heat equation:\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "v_t &= \\nu v_{xx}, && x\\in(0,1),\\ t>0, \\tag{1.2.1}\\\\\n",
    "v(x,0) &= f(x), && x\\in[0,1], \\tag{1.2.2}\\\\\n",
    "v(0,t) &= a(t),\\quad v(1,t)=b(t), && t\\ge 0. \\tag{1.2.3}\n",
    "\\end{align}\n",
    "\n",
    "where $f(0)=a(0)$, and $f(1)=b(0)$.\n",
    "\n",
    "We derived a F.T.C.S. scheme:\n",
    "\n",
    "$$\n",
    " u^{n+1}_k =  u^{n}_k + \\nu \\frac{\\Delta t}{\\Delta x^2}\\left(u_{k-1}^n -2 u_k^n + u_{k+1}^n \\right) \\tag{1.2.6}\n",
    "$$\n",
    "\n",
    "With the Initial Condition (I.C.) and Boundary Conditions (B.C.) that can be approximated by:\n",
    "\n",
    "$$\n",
    "u^{0}_k = f(k \\Delta x), \\quad k = 0, \\ldots, M \\quad (\\textrm{I.C.}) \\tag{1.2.7}\n",
    "$$\n",
    "\n",
    "$$\n",
    "u^{n+1}_0 = a( (n+1) \\Delta t), \\quad n = 0, \\ldots \\quad (\\textrm{B.C. on the left endpoint}) \\tag{1.2.8}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "u^{n+1}_M = b( (n+1) \\Delta t), \\quad n = 0, \\ldots (\\textrm{B.C. on the right endpoint}) \\tag{1.2.9}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3df2955",
   "metadata": {},
   "source": [
    "Of course, this is not the only possible approximation. We could have chosen different schemes. We will see more in the future. For now, let's see how to assess the _goodness_ of this numerical approximation.\n",
    "\n",
    "- Let's see how well the difference equation (1.2.6) approximates the partial differential equation (1.2.1). \n",
    "- We will use again the Taylor series expansion to do this\n",
    "\n",
    "Recall that to approximate the temporal derivative, we have used a simple forward finite difference:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial {u^n}^F}{\\partial t} \\approx \\frac{ u^{n+1} - u^{n}}{\\Delta t} + O(\\Delta t) \\tag{1.2.4}\n",
    "$$\n",
    "\n",
    "For the Taylor expansion:\n",
    "\n",
    "$$\n",
    "v^{n+1}_k = v(k \\Delta x, (n+1) \\Delta t) \\approx v(k \\Delta x, n \\Delta t) + \\frac{\\partial v}{\\partial t} (k \\Delta x, n \\Delta t) \\frac{\\Delta t}{1!} + \\frac{\\partial^2 v}{\\partial t^2} (k \\Delta x, n \\Delta t) \\frac{\\Delta t^2}{2!} + \\ldots\n",
    "$$\n",
    "\n",
    "(where we use the letter $v$ for the solution to the analytic partial differential equation and $u$ for the discrete approximated solution). \n",
    "\n",
    "So, \n",
    "\n",
    "$$\n",
    "\\frac{ v^{n+1}_k - v^{n}_k}{\\Delta t} = \\frac{\\partial v}{\\partial t} (k \\Delta x, n \\Delta t) + \\frac{\\Delta t}{2} \\left( \\frac{\\partial^2 v}{\\partial t^2} \\right)^n_k + \\ldots\n",
    "$$\n",
    "\n",
    "Written with the big-$O$ notation, we see that the order of what is left is:\n",
    "\n",
    "$$\n",
    "\\frac{ v^{n+1}_k - v^{n}_k}{\\Delta t} = \\frac{\\partial v}{\\partial t} (k \\Delta x, n \\Delta t) + O(\\Delta t)\n",
    "$$\n",
    "\n",
    "This expression assumes that the higher-order derivatives of $v$ at $(k \\Delta x,n \\Delta t) $ are bounded.\n",
    "\n",
    "This Taylor expansion of $v(k \\Delta x, (n+1) \\Delta t)$ shows what we are _throwing away_ when we replace $v_t$ in the PDE with $\\frac{ u^{n+1}_k - u^{n}_k}{\\Delta t}$.\n",
    "\n",
    "- We note that for the big-$O$ notation, a function $f(s) = O(\\phi(s))$ for $s \\in S$, if there exists a constant $C$ such that $|f(s)| \\leq C |\\phi(s)|$, $\\forall s \\in S$.\n",
    "    * The constant $C$ can be very large. It will be large for problems in which the solution has sudden changes with respect to time. But generally, for $\\Delta t$ sufficiently small, we are throwing away things of the order of $\\Delta t$, so that the finite difference scheme gives us a decent approximation of the $v_t$ derivative. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eae0a4b",
   "metadata": {},
   "source": [
    "The same approach can be used to show that \n",
    "\n",
    "$$\n",
    "\\frac{ v^{n}_{k+1} - v^{n}_k}{\\Delta x} = \\frac{\\partial v}{\\partial x} (k \\Delta x, n \\Delta t) + O(\\Delta x) ,\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{ v^{n}_{k} - v^{n}_{k-1}}{\\Delta x} = \\frac{\\partial v}{\\partial x} (k \\Delta x, n \\Delta t) + O(\\Delta x) ,\n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "\\frac{ v^{n}_{k+1} - v^{n}_{k-1}}{\\Delta x} = \\frac{\\partial v}{\\partial x} (k \\Delta x, n \\Delta t) + O(\\Delta x^2) .\n",
    "$$\n",
    "\n",
    "We note that the centered difference approximates the first derivative with respect to $x$ more accurately than either of the _one-sided differences_. In fact, the size of what is left is $O( \\Delta x^2 )$ versus $\\Delta x$.\n",
    "\n",
    "For the second-order derivative, we have seen:\n",
    "\n",
    "$$\n",
    "\\frac{v_{k+1}^n -2 v_k^n + v^n_{k-1}}{\\Delta x^2} = \\frac{\\partial^2 v }{\\partial x^2}(k \\Delta x, n \\Delta t) + O(\\Delta x^2)\n",
    "$$\n",
    "\n",
    "Putting it all together the PDE (1.2.1) is approximated by\n",
    "\n",
    "$$\n",
    "v_t(k \\Delta x, n \\Delta t) - \\nu v(k \\Delta x, n \\Delta t) = \\frac{ v^{n+1}_k - v^{n}_k}{\\Delta t} - \\frac{v_{k+1}^n -2 v_k^n + v^n_{k-1}}{\\Delta x^2} + \\underbrace{O(\\Delta t)+ O(\\Delta x^2)}_{\\textrm{truncation error} } \\tag{1.2.10}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fced3d0",
   "metadata": {},
   "source": [
    "- We say that the difference equation (1.2.10) approximates the PDE (1.2.1) to the _first order_ in $\\Delta t$ and _second order_ in $\\Delta x$.\n",
    "\n",
    "- Another way to view (1.2.10) is that if $v=v(x,t)$ is a _solution to the PDE_ (so that the LHS of (1.2.10) is zero), then $v$ satisfies the difference equation to the _first order_ in $\\Delta t$ and _second order_ in $\\Delta x$.\n",
    "\n",
    "- Either way, we see that eq. (1.2.10) shows how well the difference equation approximates the PDE. \n",
    "\n",
    ":::{note}\n",
    "- We should note that this in _no way_ tells us how well the solution to the difference equation approximates the solution to the PDE (which is a notion of **convergence**).\n",
    "- This is a very important topic that we will investigate. We will claim at this time that the solution to the difference scheme will _generally_ approximate the solution to the PDE to the same order that the difference scheme approximates the partial differential equation.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7b8686",
   "metadata": {},
   "source": [
    "## 3. The leapfrog scheme\n",
    "\n",
    "Can we do better than approximation (1.2.10)?\n",
    "\n",
    "So far I have said that this is just a potential approximation to the PDE. Of course, it is not the only one.\n",
    "\n",
    "What if we used a centered difference for the temporal derivative?\n",
    "\n",
    "We can use\n",
    "$$\n",
    "\\frac{ u^{n+1}_k - u^{n-1}_k}{2 \\Delta t}\n",
    "$$\n",
    "\n",
    "as approximation of $v_t$. The difference equation then becomes:\n",
    "\n",
    "$$\n",
    "u^{n+1}_k = u^{n-1}_k + \\frac{2 \\nu \\Delta t}{\\Delta x^2} \\left( u_{k+1}^n -2 u_k^n + u^n_{k-1}  \\right)  \\quad \\textrm{{(C.T.C.S.)}} \\tag{1.2.11}\n",
    "$$\n",
    "\n",
    "which is **second order** in both **space and time**.\n",
    "\n",
    "This difference scheme is called the **leapfrog scheme** and is referred to as a three-step (or three-level) method.\n",
    "\n",
    "- For which values of $n$ is the difference equation (1.2.11) valid?\n",
    "- How to start this method? We note that now we not only need _one_ initial condition, for $u_k^0$. How many do we need?\n",
    "\n",
    "\n",
    "Before we move on, let us introduce some notation that might be handy.\n",
    "\n",
    "We define\n",
    "\n",
    "$$\n",
    "\\delta_{+}u_k = u_{k+1} - u_{k}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\delta_{-}u_k = u_{k} - u_{k-1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\delta_{0}u_k = u_{k+1} - u_{k-1}\n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "\\delta^2 u_k = u_{k+1} - 2 u_{k} + u_{k-1}\n",
    "$$\n",
    "\n",
    "to be the forward, backward, centered, and centered second-order difference operators, respectively. \n",
    "\n",
    "With this notation, we can rewrite (1.2.6) as\n",
    "\n",
    "$$\n",
    "u_k^{n+1} = u_k^n + \\frac{\\nu \\Delta t }{\\Delta x^2} \\delta^2 u^n_k\n",
    "$$\n",
    "\n",
    "and is referred to as the forward in time, centered in space (FTCS) scheme for solving the heat equation (1.2.1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1f3195",
   "metadata": {},
   "source": [
    "## 4. Introduction to Accuracy\n",
    "\n",
    "Consider the boundary value problem (Poisson's problem): find $u$:\n",
    "\n",
    "\\begin{gather*} -\\frac{\\partial^2 u}{\\partial x^2} = f(x), \\quad x \\in \\Omega = (-1,1) \\\\\n",
    "u(-1) = a, \\quad \\frac{ \\partial u}{\\partial x}(1) = b .\n",
    "\\end{gather*}\n",
    "\n",
    "We say\n",
    "* $f(x)$ is the \"forcing\"\n",
    "* the left boundary condition is a **non-homegenous Dirichlet** boundary condition (it imposes a condition on the unknown $u$)\n",
    "* the right boundary condition is a **non-homegenous Neumann** boundary condition (it imposes a condition on the first-order derivative of the unknown $\\partial u / \\partial x$)\n",
    "\n",
    "We need to choose\n",
    "* how to represent $u(x)$, including evaluating it on the boundary,\n",
    "* how to compute derivatives of $u$,\n",
    "* in what sense to ask for the differential equation to be satisfied,\n",
    "* where to evaluate $f(x)$ or integrals thereof,\n",
    "* how to enforce boundary conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1abdb2",
   "metadata": {},
   "source": [
    "### 4.1 Finite Differences (FD)/collocation approach\n",
    "\n",
    "We have seen that we can represent the function $u(x)$ by its values $u_i = u(x_i)$ at a discrete set of points $$ -1 = x_1 < x_2 < \\dotsb < x_n = 1 . $$ \n",
    "\n",
    "(where I am changing the indices from $0, 1, \\ldots M$ to $1, 2, \\ldots n$ for simplicity to match the code below, since Julia is one-index based).\n",
    "* The FD framework does not uniquely specify the solution values at other points\n",
    "* Compute derivatives at $x_i$ via differencing formulas involving a finite number of neighbor points (independent of the total number of points $n$).\n",
    "\n",
    "* FD methods ask for the differential equation to be satisfied pointwise at each $x_i$ in the _interior_ of the domain.\n",
    "* Evaluate the forcing term $f$ pointwise at $x_i$.\n",
    "* Approximate derivatives at discrete boundary points ($x_1 =0$ and $x_n = 1$ above), typically using one-sided differencing formulas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa08e171",
   "metadata": {},
   "source": [
    "#### Computing a derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f89b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "using LaTeXStrings\n",
    "default(linewidth=3)\n",
    "default(legendfontsize=12)\n",
    "\n",
    "n = 41\n",
    "h = 6 / (n - 1)\n",
    "x = LinRange(-3, 3, n)\n",
    "u = sin.(x) # Note: dot operator allows functions in Julia to accept arrays as arguments and return arrays (it applies the function point-wise on all entries of the array).\n",
    "plot(x, u, marker=:circle, label = L\"\\sin(x)\", xlabel = \"x\", ylabel = \"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88281772",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_x = cos.(x) # analytic first-order derivative\n",
    "fd_u_x = (u[2:end] - u[1:end-1]) / h # What does this do?\n",
    "\n",
    "plot(x, u_x, label = L\"\\cos(x)\")\n",
    "plot!(x[1:end-1], fd_u_x, marker=:circle, label= \"FD\", xlabel = \"x\", ylabel = \"y\") # Note: the \"!\" overlays a curve to an existing plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89392ccf",
   "metadata": {},
   "source": [
    "#### How accurate is it?\n",
    "\n",
    "Without loss of generality, we'll approximate $u'(x_i = 0)$, taking $h = x_{i+1} - x_i$. Remember, Taylor's expansion:\n",
    "\n",
    "$$ u(x) = u(0) + u'(0)x + u''(0)x^2/2! + O(x^3)$$\n",
    "\n",
    "and substitute into the differencing formula\n",
    "\n",
    "$$ \\begin{split} u'(0) \\approx \\frac{u(h) - u(0)}{h} = h^{-1} \\Big( u(0) + u'(0) h + u''(0)h^2/2 + O(h^3) - u(0) \\Big) \\\\\n",
    "= u'(0) + u''(0)h/2 + O(h^2) . \\end{split}$$\n",
    "\n",
    "Evidently the error in this approximation is $u''(0)h/2 + O(h^2)$. \n",
    "* We say this method is **first order accurate**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad5d29b",
   "metadata": {},
   "source": [
    "## 5. Introduction to Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebea5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = big(1e-15) # Represent this number with maximal precision (much better than double)\n",
    "@show big(1+x)\n",
    "@show log(1 + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653bb283",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot([h -> log(1+h), log1p], xlim=(-1e-15, 1e-15), label = [\"y = log(1 + x)\" \"y = log1p(x)\"]) # What's going on?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96e06f1",
   "metadata": {},
   "source": [
    "We can see that a more stable implementation (he Julia built-in `log1p` function) produces a more accurate and \"error-free\" result.\n",
    "\n",
    "### Reliable = well-conditioned and stable algorithm\n",
    "\n",
    "#### Mathematical functions $f(x)$ can be ill-conditioned (big $\\kappa$)\n",
    "* Modeling is how we turn an abstract question into a mathematical function\n",
    "* We want well-conditioned models (small condition number)\n",
    "* Some systems are intrinsically sensitive (chaotic): fracture, chaotic systems, combustion\n",
    "\n",
    "#### Algorithms `f(x)` can be unstable\n",
    "* Unreliable, though sometimes practical\n",
    "* Unstable algorithms are constructed from ill-conditioned parts\n",
    "\n",
    "### Other Finite Difference (FD) method examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad251f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff1l(x, u) = x[2:end],   (u[2:end] - u[1:end-1]) ./ (x[2:end] - x[1:end-1]) # first-order accurate one-sided left FD\n",
    "diff1r(x, u) = x[1:end-1], (u[2:end] - u[1:end-1]) ./ (x[2:end] - x[1:end-1]) # first-order accurate one-sided right FD\n",
    "diff1c(x, u) = x[2:end-1], (u[3:end] - u[1:end-2]) ./ (x[3:end] - x[1:end-2]) # second-order accurate centered FD\n",
    "difflist = [diff1l, diff1r, diff1c]\n",
    "\n",
    "n = 40 \n",
    "h = 2 / (n - 1)\n",
    "x = LinRange(-3, 3, n)\n",
    "u = sin.(x)\n",
    "fig = plot(cos, xlims=(-3, 3), label = L\"\\cos(x)\")\n",
    "for d in difflist\n",
    "    xx, yy = d(x, u)\n",
    "    plot!(fig, xx, yy, marker=:circle, label=d)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d857d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb1d135",
   "metadata": {},
   "source": [
    "Where is the blue (analytical) curve?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412a734e",
   "metadata": {},
   "source": [
    "### Accuracy: Measuring errors\n",
    "\n",
    "#### Absolute and Relative Errors\n",
    "\n",
    "### Absolute Error\n",
    "$$ \\lvert \\tilde f(x) - f(x) \\rvert $$\n",
    "\n",
    "where $\\tilde f(x)$ is the computed, approximate solution and $f(x)$ is the analytical one.\n",
    "\n",
    "### Relative Error\n",
    "$$ \\frac{\\lvert \\tilde f(x) - f(x) \\rvert}{\\lvert f(x) \\rvert} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac40340",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"LinearAlgebra\") # adds the LinearAlgebra.jl package to your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946d041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "\n",
    "\n",
    "grids = 2 .^ (2:10)\n",
    "hs = 1 ./ grids\n",
    "function refinement_error(f, fprime, d)\n",
    "    error = []\n",
    "    for n in grids\n",
    "        x = LinRange(-3, 3, n)\n",
    "        xx, yy = d(x, f.(x))\n",
    "        push!(error, norm(yy - fprime.(xx), 2)/sqrt(n))\n",
    "    end\n",
    "    error\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e19b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot(xscale=:log10, yscale=:log10)\n",
    "for d in difflist\n",
    "    error = refinement_error(sin, cos, d)\n",
    "    plot!(fig, hs, error, marker=:circle, label=d)\n",
    "end\n",
    "plot!(fig, hs, [hs hs .^ 2], label=[\"\\$h\\$\" \"\\$h^2\\$\"], xlabel = \"h\", ylabel = \"error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55adbada",
   "metadata": {},
   "source": [
    "**Interpretation**: We can see that:\n",
    "* The one-sided left and right FD schemes are only  **first order accurate** (their error behaves like the $h$ reference line)\n",
    "    - This means that the absolute error is **halved** if the grid spacing is halved. So the method converges **linearly**\n",
    "* The centered FD scheme is **second order accurate** (its error behaves like the $h^2$ reference line)\n",
    "    - This means that the number of correct digits doubles every time we consider a smaller (halved) grid spacing. That is, the absolute error is **divided by 4** if the grid spacing is halved.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb91e8c",
   "metadata": {},
   "source": [
    "## 6. Introduction to Conditioning\n",
    "\n",
    "Keeping in mind roundoff errors and floating point arithmetic (refer to [Lecture 4](https://sdsu-math693b.github.io/spring26/lectures/module1-4_intro_to_julia.html#errors)), to how many digits can you trust a computer's output of\n",
    "\n",
    "$$ \\sin(\\pi/3) $$\n",
    "\n",
    "and\n",
    "\n",
    "$$ \\sin(10^{10} + \\pi/3), $$\n",
    "\n",
    "if it uses double precision?\n",
    "\n",
    "This problem (evaluating $\\sin$ with a large argument) is **ill-conditioned**. Even the best algorithm _cannot_ be expected to produce a more accurate answer.\n",
    "\n",
    "### Example 6.1:\n",
    "Computing $e^x$\n",
    "\n",
    "$$ e^x = \\sum_{k=0}^{\\infty} x^k/k! = 1 + x + \\frac{x^2}{2!} + \\frac{x^3}{3!} + \\dotsb$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3779f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "function myexp(x)\n",
    "    sum = 1\n",
    "    for k in 1:100\n",
    "        sum += x^k / factorial(big(k))\n",
    "    end\n",
    "    return sum\n",
    "end\n",
    "myexp(1) - exp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6909fd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "function myexp(x)\n",
    "    sum = 0\n",
    "    term = 1\n",
    "    n = 1\n",
    "    while sum + term != sum\n",
    "        sum += term\n",
    "        term *= x / n\n",
    "        n += 1\n",
    "    end\n",
    "    sum\n",
    "end\n",
    "myexp(1) - exp(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e79b2ff",
   "metadata": {},
   "source": [
    "- How accurate is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d241eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(myexp, xlims=(-2, 2), label = \"exp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b1d1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(exp, xlims=(-1e-15, 1e-15), linestyle=:solid, label = \"exp\")\n",
    "plot!(myexp, xlims=(-1e-15, 1e-15), linestyle=:dash, label=\"myexp\") # the bang operator overlays the second plot in the same figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87928ce",
   "metadata": {},
   "source": [
    "What's happening?\n",
    "\n",
    "* We're computing $f(x) = e^x$ for values of $x$ near zero.\n",
    "* This function is well approximated by $1 + x$.\n",
    "* Values of $y$ near 1 cannot represent every value.\n",
    "* After rounding, the error in our computed output $\\tilde f(x)$ is of order $\\epsilon_{\\text{machine}}$.\n",
    "\n",
    "Suppose I want to compute $e^x - 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a17767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot([x -> myexp(x) - 1 , x -> x],\n",
    "     xlims=(-1e-15, 1e-15), label=[\"myexp\" \"y=x\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8e9ec6",
   "metadata": {},
   "source": [
    "What now?\n",
    "\n",
    "* We're capable of representing outputs with 16 digits of accuracy\n",
    "* Yet our algorithm `myexp(x) - 1` can't find them\n",
    "* We can't recover without modifying our code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7ade9c",
   "metadata": {},
   "source": [
    "Let's modify the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7429fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "function myexpm1(x)\n",
    "    sum = 0\n",
    "    term = x\n",
    "    n = 2\n",
    "    while sum + term != sum\n",
    "        sum += term\n",
    "        term *= x / n\n",
    "        n += 1\n",
    "    end\n",
    "    sum\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb23f39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(myexpm1, xlims=(-1e-15, 1e-15), label=\"myexpm1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f56924",
   "metadata": {},
   "source": [
    "#### Plot relative error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93e98c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "function relerror(x, f, f_ref)\n",
    "    fx = f(x)\n",
    "    fx_ref = f_ref(x)\n",
    "    max(abs(fx - fx_ref) / abs(fx_ref), 1e-17)\n",
    "end\n",
    "badexpm1(t) = exp(t) - 1\n",
    "plot(x -> relerror(x, badexpm1, expm1), yscale=:log10, xrange=(-1e-15, 1e-15), label = \"rel error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a34180",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(x -> (1 + x) - 1, xlims=(-1e-15, 1e-15), label = \"y = 1 + x - 1\")\n",
    "plot!(x -> x, label=\"y = x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86055d3f",
   "metadata": {},
   "source": [
    "## 6.1 Condition number\n",
    "\n",
    "\n",
    "> What sort of functions cause small errors to become big?\n",
    "\n",
    "Consider a function $f: X \\to Y$ and define the **absolute condition number**\n",
    "$$ \\hat\\kappa = \\lim_{\\delta \\to 0} \\max_{|\\delta x| < \\delta} \\frac{|f(x + \\delta x) - f(x)|}{|\\delta x|} = \\max_{\\delta x} \\frac{|\\delta f|}{|\\delta x|}. $$\n",
    "If $f$ is differentiable, then $\\hat\\kappa = |f'(x)|$.\n",
    "\n",
    "Floating point arithmetic offers relative accuracy, so it's more useful to discuss **relative condition number**,\n",
    "$$ \\kappa = \\max_{\\delta x} \\frac{|\\delta f|/|f|}{|\\delta x|/|x|}\n",
    "= \\max_{\\delta x} \\Big[ \\frac{|\\delta f|/|\\delta x|}{|f| / |x|} \\Big] $$\n",
    "or, if $f$ is differentiable,\n",
    "$$ \\kappa = |f'(x)| \\frac{|x|}{|f|} . $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180c078f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f(x) = x - 1; fprime(x) = 1\n",
    "plot(x -> abs(fprime(x)) * abs(x) / abs(f(x)), xlims=(0, 2), label = \"kappa for x-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad72d26",
   "metadata": {},
   "source": [
    "### Example:\n",
    "Back to $f(x) = e^x - 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cac404",
   "metadata": {},
   "outputs": [],
   "source": [
    "f(x) = exp(x) - 1\n",
    "fprime(x) = exp(x)\n",
    "plot(x -> abs(fprime(x)) * abs(x) / abs(f(x)), label = \"kappa for exp(x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44624a0",
   "metadata": {},
   "source": [
    "What does it mean?\n",
    "\n",
    "* The function $f(x) = e^x - 1$ is well-conditioned\n",
    "* The function $f_1(x) = e^x$ is well-conditioned\n",
    "* The function $f_2(x) = x - 1$ is ill-conditioned for $x \\approx 1$\n",
    "\n",
    "#### The **algorithm** is unstable\n",
    "\n",
    "* `f(x) = exp(x) - 1` is unstable\n",
    "* Algorithms are made from elementary operations\n",
    "* Unstable algorithms _do_ something ill-conditioned\n",
    "\n",
    "#### A stable algorithm\n",
    "\n",
    "We used the series expansion previously.\n",
    "* accurate for small $x$\n",
    "* less accurate for negative $x$ (see activity)\n",
    "* we could use symmetry to fix\n",
    "* inefficient because we have to sum lots of terms\n",
    "\n",
    "Standard math libraries define a more efficient stable variant, $\\texttt{expm1}(x) = e^x - 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d41274",
   "metadata": {},
   "outputs": [],
   "source": [
    "expm1(-40) + 1 # this way, using the built-in, stable variant, it is exactly 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906dd9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp(-40) # almost zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd0a640",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot([x -> exp(x) - 1,\n",
    "      x -> expm1(x)],\n",
    "    xlims = (-1e-15, 1e-15), label = [\"y = exp(x) - 1\" \"y = expm1(x)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62ed3d8",
   "metadata": {},
   "source": [
    "### Reliable = well-conditioned and stable algorithm\n",
    "\n",
    "#### Mathematical functions $f(x)$ can be ill-conditioned (big $\\kappa$)\n",
    "* Modeling is how we turn an abstract question into a mathematical function\n",
    "* We want well-conditioned models (small $\\kappa$)\n",
    "* Some systems are intrinsically sensitive (chaotic): fracture, chaotic systems, combustion\n",
    "\n",
    "#### Algorithms `f(x)` can be unstable\n",
    "* Unreliable, though sometimes practical\n",
    "* Unstable algorithms are constructed from ill-conditioned parts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9b28f2",
   "metadata": {},
   "source": [
    "## 7. Lax equivalence theorem\n",
    "\n",
    "In summary,\n",
    "- **Consistency**: describes how well the numerical scheme aproximates the PDE (if the Finite Difference (FD) discretization is at least of order 1 $\\implies$ it is consistent --- The residual reduces under grid refinement). \n",
    "- **Stability**: Numerical stability concerns how errors introduced during the execution of an algorithm affect the result. It is a property of an algorithm rather than the problem being solved (check [Higham's blog](https://nhigham.com/2020/08/04/what-is-numerical-stability/)). This gets subtle for problems like incompressible materials or contact mechanics.\n",
    "- **Convergence**: When the solution of the approximated equation approaches the actual solution of the continuous equation.\n",
    "\n",
    ":::{admonition} **[Lax equivalence Theorem](https://en.wikipedia.org/wiki/Lax_equivalence_theorem)**:\n",
    "A consistent finite difference scheme for a partial differential equation for which the initial value problem is well-posed is convergent _if and only if_ it is stable. \n",
    ":::\n",
    "\n",
    "In practice, we have the two one-way implications and the Lax equivalence theorem puts them together to form a _necessary and sufficient_ codition:\n",
    "\n",
    ">\tConsistency + Convergence $\\implies$ Stability \\\n",
    ">\tConsistency + Stability $\\implies$ Convergence\\\n",
    "Hence, \\\n",
    ">   **Lax equivalence theorem**:\n",
    ">\tConsistency + Convergence $\\iff $ Stability\n",
    "\n",
    "This theorem is extremely useful:\n",
    "\n",
    "- Checking consistency is straight-forward (Taylor expansions).\n",
    "\n",
    "- We are going to introduce tools (based on Fourier transforms) which\n",
    "make checking stability quite easy.\n",
    "\n",
    "- Thus, if the problem is well-posed, we get the more difficult (and\n",
    "desirable) result, **convergence**, by checking two\n",
    "(relatively) easy things: consistency and stability.\n",
    "\n",
    "- The relationship is one-to-one, hence only consistent and stable\n",
    "schemes need to be considered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729abba3",
   "metadata": {},
   "source": [
    "## 8. Higher-order schemes: the Method of Undetermined Coefficients\n",
    "\n",
    "So far, for the heat equation (1.2.1) we have derived two numerical schemes. The first one, FTCS, (1.2.6),\n",
    "\n",
    "$$\n",
    "u^{n+1}_k =  u^{n}_k + \\nu \\frac{\\Delta t}{\\Delta x^2}\\left(u_{k-1}^n -2 u_k^n + u_{k+1}^n \\right) \\quad \\textrm{{(F.T.C.S.)}} \\tag{1.2.6}\n",
    "$$\n",
    "\n",
    "And the second one, CTCS, (1.2.11),\n",
    "\n",
    "$$\n",
    "u^{n+1}_k = u^{n-1}_k + \\frac{2 \\nu \\Delta t}{\\Delta x^2} \\left( u_{k+1}^n -2 u_k^n + u^n_{k-1}  \\right)  \\quad \\textrm{{(C.T.C.S.)}} \\tag{1.2.11}\n",
    "$$\n",
    "\n",
    "- It is possible to approximate derivatives to any arbitrary order of accuracy.\n",
    "\n",
    ":::{note}\n",
    "- Order of accuracy $\\neq$ order of the derivative\n",
    ":::\n",
    "\n",
    "To derive any order approximation Finite Difference (FD) scheme, we can use a method called the Method of Undetermined Coefficients. \n",
    "\n",
    "We first start by noting that for the derivatives we have seen so far (first-order time derivative, and first-order and second-order spatial derivatives) we always needed one more grid point than the desired order of accuracy. For instance, to obtain a first-order accurate scheme of a first order derivative, we needed two grid points. And, for a second-order accurate scheme of a second order derivative, we needed three grid points. \n",
    "\n",
    "This builds up intuition that, for instance, we could not approximate $v_{xx}$ to the fourth order of accuracy by using only three grid points: $x = k \\Delta x$, and $x = (k \\pm 1)\\Delta x$. We shall see that to have a fourth-order approximation of $v_{xx}$, we need a $5$-point stencil touching the points $x = k \\Delta x$, $x = (k \\pm 1)\\Delta x$, and $x = (k \\pm 2)\\Delta x$.\n",
    "\n",
    "- To have a $k$-order approximation in 1D, we need $(k+1)$ grid points.\n",
    "\n",
    "Let's re-derive the second-order approximation of the secon derivative $u_{xx}$. We know that we need three coefficients.\n",
    "\n",
    "We can write the ansatz \n",
    "\n",
    "$$\n",
    "\\frac{\\partial^2 u}{\\partial x^2} \\approx a u_k + b u_{k+1} + c u_{k+2} \\tag{1.2.12}\n",
    "$$\n",
    "\n",
    "Or, we could have equivalently used the $x = k \\Delta x$, and $x = (k \\pm 1)\\Delta x$ grid points (symmetric w.r.t. the reference point $x_k$)\n",
    "\n",
    "$$\n",
    "\\frac{\\partial^2 u}{\\partial x^2} \\approx a u_{k-1} + b u_{k} + c u_{k+1}  \\tag{1.2.13}\n",
    "$$\n",
    "\n",
    "but then we need to be careful about the negative sign in the Taylor expansion!\n",
    "\n",
    "Let's stick with (1.2.12) for now and use Taylor expansion around the point $u_k$:\n",
    "\n",
    "$$\n",
    "u_{k+1} = u_k + \\Delta x u'_k + \\frac{1}{2} \\Delta x^2 u''_k + O(\\Delta x^3)\n",
    "$$\n",
    "\n",
    "$$\n",
    "u_{k+2} = u_k + 2 \\Delta x u'_k + \\frac{1}{2} \\left(2 \\Delta x \\right)^2 u''_k + O((2 \\Delta x)^3)\n",
    "$$\n",
    "\n",
    "Let's plug them in (1.2.12)\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial^2 u}{\\partial x^2} &\\approx  a u_k + b \\left( u_k + \\Delta x u'_k + \\frac{1}{2} \\Delta x^2 u''_k + O(\\Delta x^3) \\right) + c \\left( u_k + 2 \\Delta x u'_k + 2 \\Delta x^2  u''_k + O(8 \\Delta x^3) \\right) = \\\\\n",
    "&= (a+b+c) u_k + (b \\Delta x + 2c \\Delta x) u'_k + \\left( \\frac{1}{2} b \\Delta x^2  +2c \\Delta x^2 \\right) u''_k + (b+c) O(\\Delta x^3)\n",
    "\\end{align*}\n",
    "\n",
    "Equating the like-term coefficients on both sides of the equation, gives us the following constraints:\n",
    "\n",
    "\\begin{align*}\n",
    "\\textrm{(i) } & a + b + c = 0 \\\\\n",
    "\\textrm{(ii) } & \\underbrace{\\Delta x}_{\\neq 0} (b+2c) =0 \\implies b = -2c \\\\\n",
    "\\textrm{(iii) } &  \\frac{1}{2} b \\Delta x^2 + 2c \\Delta x^2 = 1 \\\\ \n",
    "\\end{align*}\n",
    "\n",
    "We solve (ii) and substitute in (i) and (iii):\n",
    "\n",
    "\\begin{align*}\n",
    "\\textrm{(i) } & a - c = 0 \\implies a = c \\\\\n",
    "\\textrm{(ii) } &  b = -2c \\\\\n",
    "\\textrm{(iii) } &  -c \\Delta x^2 + 2c \\Delta x^2 = 1 ; \\quad c \\Delta x^2 = 1 \\implies c = \\frac{1}{\\Delta x^2}\\\\ \n",
    "\\end{align*}\n",
    "\n",
    "Therefore,\n",
    "\\begin{align*}\n",
    "\\textrm{(i) } & a =  \\frac{1}{\\Delta x^2}\\\\\n",
    "\\textrm{(ii) } &  b = -2 \\frac{1}{\\Delta x^2} \\\\\n",
    "\\textrm{(iii) } & c = \\frac{1}{\\Delta x^2}\\\\ \n",
    "\\end{align*}\n",
    "\n",
    "Hence, we find\n",
    "\n",
    "$$\n",
    "\\frac{\\partial^2 u}{\\partial x^2} \\approx \\frac{  u_{k} + -2 u_{k+1} +  u_{k+2}}{\\Delta x^2} \n",
    "$$\n",
    "\n",
    "Or, shifting indices, we see the familiar second-order centered scheme:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial^2 u}{\\partial x^2} \\approx \\frac{  u_{k-1} + -2 u_{k} +  u_{k+1}}{\\Delta x^2} \n",
    "$$\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
